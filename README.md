# **NLP Model Evaluation**

## ğŸ“Œ **Project Overview**
This project focuses on evaluating various deep learning models for text classification. Different word embedding techniques (**Word2Vec, FastText, TF-IDF**) were tested along with recurrent neural network architectures (**LSTM, GRU, SimpleRNN**). The objective is to determine the best-performing model in terms of accuracy and generalization.

## ğŸ† **Best Model**  
âœ… **FastText + GRU (70/30)**  
- Achieved the highest test accuracy, making it the best-performing model.

## ğŸ“‚ **Project Structure**
```
â”œâ”€â”€ data/                 # Dataset files
â”œâ”€â”€ models/               # Saved trained models
â”œâ”€â”€ notebooks/            # Jupyter notebooks for exploration
â”œâ”€â”€ src/                  # Source code for training and evaluation
â”‚   â”œâ”€â”€ train_model.py    # Model training script
â”‚   â”œâ”€â”€ evaluate.py       # Model evaluation script
â”‚   â”œâ”€â”€ preprocess.py     # Data preprocessing utilities
â”œâ”€â”€ requirements.txt      # Required dependencies
â”œâ”€â”€ README.md             # Project documentation
```

## ğŸš€ **How to Use**

### 1ï¸âƒ£ **Clone the Repository**
```bash
git clone https://github.com/your-username/nlp-model-evaluation.git
cd nlp-model-evaluation
```

### 2ï¸âƒ£ **Install Dependencies**
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ **Run the Model Training & Evaluation**
```bash
python src/train_model.py
```

## ğŸ“œ **License**
This project is open-source and available under the **MIT License**.

---

â­ **Feel free to fork this repository, improve the models, and contribute!** ğŸš€
